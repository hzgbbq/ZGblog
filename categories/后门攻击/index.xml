<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>后门攻击 on 泽港—GANG</title>
        <link>https://hzgbbq.github.io/ZGblog/categories/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/</link>
        <description>Recent content in 后门攻击 on 泽港—GANG</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>泽港-GANG</copyright>
        <lastBuildDate>Mon, 23 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://hzgbbq.github.io/ZGblog/categories/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>论文阅读：基于深度学习的医学图像加解密网络的后门攻击</title>
        <link>https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%8A%A0%E8%A7%A3%E5%AF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/</link>
        <pubDate>Mon, 23 Sep 2024 00:00:00 +0000</pubDate>
        
        <guid>https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%8A%A0%E8%A7%A3%E5%AF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/</guid>
        <description>&lt;img src="https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%8A%A0%E8%A7%A3%E5%AF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/title.jpg" alt="Featured image of post 论文阅读：基于深度学习的医学图像加解密网络的后门攻击" /&gt;&lt;h2 id=&#34;论文信息&#34;&gt;论文信息
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;标题：Backdoor Attack on Deep Learning-Based Medical Image Encryption and Decryption Network&lt;/li&gt;
&lt;li&gt;发表年份：05 October 2023&lt;/li&gt;
&lt;li&gt;发表期刊/会议：IEEE Transactions on Information Forensics and Security(Volume: 19)Page(s): 280 - 292&lt;/li&gt;
&lt;li&gt;DOI 链接: 10.1109/TIFS.2023.3322315&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;摘要概述&#34;&gt;摘要概述
&lt;/h2&gt;&lt;p&gt;本文主要研究了对医疗影像加密和解密模型的攻击，提出了一种加解密网络后门攻击范式，并分别针对加解密场景设计了相应的攻击方式。&lt;/p&gt;
&lt;p&gt;在攻击加密模型中，采用了后门鉴别器，它与普通鉴别器进行随机训练，以混淆加密过程，最终导致加密失败。&lt;/p&gt;
&lt;p&gt;在解密场景中，替换了部分子网参数，解密带有触发器的图像时，使图像解密失败。&lt;/p&gt;
&lt;p&gt;本文还做了两点革新：一是考虑到参数替换会导致模型性能下降，采用了模型剪枝来进一步减少参数替换量，从而增强攻击性能；二是采用图像隐写术为每张图像生成不可见的触发器，提高后门攻击的隐蔽性。&lt;/p&gt;
&lt;h2 id=&#34;研究背景与动机&#34;&gt;研究背景与动机
&lt;/h2&gt;&lt;h3 id=&#34;研究背景&#34;&gt;研究背景
&lt;/h3&gt;&lt;p&gt;1、医疗图像中包含大量敏感信息，如患者的病历、诊断图像等，这些数据一旦泄露可能带来严重的隐私风险。因此，医疗图像的加密和解密技术一直是医疗信息安全领域的重点研究方向。&lt;/p&gt;
&lt;p&gt;2、近年来，基于深度学习的医疗图像加密方法，如CycleGAN等，能够有效地实现图像的风格迁移，将医疗图像转换为难以识别的加密图像，从而提升图像的安全性。然而，现有的加密方法仍然可能受到攻击，尤其是在训练阶段引入后门的情况下。&lt;/p&gt;
&lt;h3 id=&#34;动机&#34;&gt;动机
&lt;/h3&gt;&lt;p&gt;作者通过通过三篇引文&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2112.01148&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;10&lt;/a&gt;、&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2111.12965&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;22&lt;/a&gt;、&lt;a class=&#34;link&#34; href=&#34;https://ieeexplore.ieee.org/document/9879958&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;25&lt;/a&gt;，看到了目前的后门攻击方法主要使针对监督模型，并且难以应用于半监督和无监督。同时看到了在在基于深度学习的医疗影像安全领域在抵御后门攻击能力上的缺陷。&lt;/p&gt;
&lt;h2 id=&#34;论文方法与技术&#34;&gt;论文方法与技术
&lt;/h2&gt;&lt;h3 id=&#34;相关工作&#34;&gt;相关工作
&lt;/h3&gt;&lt;h4 id=&#34;a基于深度学习的医学图像加解密网络的发展历程&#34;&gt;A.基于深度学习的医学图像加解密网络的发展历程
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;深度学习在医学图像加解密中的引入&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最早基于深度学习的医学图像加解密技术是采用卷积神经网络（CNN）进行特征提取，并将其用于加密。研究人员使用CNN从虹膜图像中提取特征，并通过纠错编码对其进行加密（Li等，2018年）。此方法通过异或操作进行图像加密。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;深度学习与混沌映射结合&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一些学者进一步发展了将深度学习与混沌映射结合的方法来增强加密效果。例如，Maniyath等人提出了一个强大的深度神经网络，该网络通过混沌映射来加密图像，能有效抵抗多种攻击。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cycle-GAN 在医学图像加解密中的应用&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cycle-GAN 被用于将医学图像的风格转化为随机分布像素的密文图像，作为加密解密网络的核心架构之一。该方法成功实现了医学图像的风格迁移和加解密。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;b后门攻击&#34;&gt;B.后门攻击
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;后门攻击概述&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;后门攻击是指攻击者在模型训练过程中植入后门，使得模型在遇到特定触发器时产生预期的行为，而在没有触发器的情况下，模型表现正常。Badnets 是最早提出的后门攻击模型之一，针对图像分类任务有效地演示了这种攻击。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;动态后门攻击&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;动态后门攻击通过改变触发器的模式和位置来增加攻击的隐蔽性。例如，Salem等人提出了动态后门攻击策略，触发器的模式和位置可以变化，增加了检测难度。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;多样化后门攻击的应用&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;除了图像分类任务外，后门攻击还可以应用于生成模型、语言模型等复杂系统。例如，张等人通过触发短语让生成模型生成特定字符串或冒犯性文本。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;对深度学习加密网络的后门攻击&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大多数研究集中在分类模型的后门攻击，然而加密和解密网络同样面临后门攻击威胁。由于加密解密任务缺乏标签，传统的后门攻击方法难以适用，新的攻击方式急需开发。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;对生成模型的挑战&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;现有的后门攻击方法对生成模型攻击存在困难，生成模型的输入需要满足多种特定限制，且现有的推理攻击难以直接应用于生成网络。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;c图片隐写术发展历程&#34;&gt;C.图片隐写术发展历程
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;隐写术简介&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隐写术是一种通过将信息隐藏在另一种数据（如图片、音频、视频等）中，避免被察觉的技术。最早提出的隐写术方法之一是**最低有效位（LSB）**技术。它通过用秘密图像的n个最重要位替换覆盖图像的n个最不重要位来实现信息嵌入。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;基于频域的隐写术方法&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;除了LSB技术，研究人员还开发了在不同频域中嵌入信息的方法，例如&lt;strong&gt;离散傅里叶变换（DFT）&lt;/strong&gt;、&lt;strong&gt;离散余弦变换（DCT）&lt;/strong&gt; 和&lt;strong&gt;离散小波变换（DWT）&lt;/strong&gt;。这些方法虽然复杂一些，但比LSB更可靠且不易被检测到。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;基于深度学习的隐写术模型&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最近，深度学习被应用于隐写术中，超越了传统技术的性能。Zhu等人开发了基于自编码器的网络来实现水印嵌入与提取。Ahmadi等人在此基础上引入了残差连接和CNN变换操作模块，以便在任何变换空间中嵌入水印。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;隐写GAN模型的引入&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Zhang等人使用生成对抗网络（GAN）提高了隐写图像的感知质量。该方法能更好地隐藏信息，且隐写图像与原始图像在视觉上几乎无差异。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;隐写术在后门攻击中的应用&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Li等人最早使用基于深度神经网络的图像隐写术生成隐蔽的后门触发器。这种攻击不仅难以被检测到，还能够绕过大多数现有的后门防御措施，因为它的触发器模式是针对具体样本的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;方法论&#34;&gt;方法论
&lt;/h3&gt;&lt;h4 id=&#34;a威胁模型&#34;&gt;A.威胁模型
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;威胁场景&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;在加密网络的场景中&lt;/strong&gt;，攻击者了解加密网络的训练过程，并且掌握部分训练数据，但不能更改网络结构。在受害者使用训练好的模型加密医学图像时，攻击者可以在输入图像上植入后门触发器，破坏加密性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在解密场景中&lt;/strong&gt;，攻击者熟悉模型的结构和内存布局，但不参与加密网络的训练。攻击者可以修改解密网络的某些参数来插入子网络，从而在输入图像中嵌入触发器时激活后门攻击 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;攻击目标&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;加密网络&lt;/strong&gt;：攻击目标是当输入图像中包含后门触发器时，网络无法将其转换为密文图像，而在没有触发器时，网络可以正常加密图像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解密网络&lt;/strong&gt;：当输入带有后门触发器的密文图像时，解密网络将输出与原始图像完全不同的图像；而当输入的密文图像不含触发器时，解密网络可以成功解密回原始图像 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;后门触发器&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;无论是加密还是解密场景，后门触发器作为攻击的标志，不应被人眼轻易识别。这种隐蔽性是后门攻击成功的关键因素。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;C:%5cUsers%5c90678%5cAppData%5cRoaming%5cTypora%5ctypora-user-images%5cimage-20240924164621725.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20240924164621725&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;实验结果与分析&#34;&gt;实验结果与分析
&lt;/h2&gt;&lt;p&gt;论文的实验设计为&amp;hellip;，使用的评价指标为&amp;hellip;。结果显示&amp;hellip;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hzgbbq.github.io/ZGblog/ZGblog/image-url&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;实验结果图&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;结论与启示&#34;&gt;结论与启示
&lt;/h2&gt;&lt;p&gt;论文得出的结论是&amp;hellip;。从中我学到了&amp;hellip;，但同时存在以下不足&amp;hellip;。&lt;/p&gt;
&lt;h2 id=&#34;个人评论与反思&#34;&gt;个人评论与反思
&lt;/h2&gt;&lt;p&gt;我认为这篇论文的贡献在于&amp;hellip;，但有些地方可以进一步改进，例如&amp;hellip;。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>

[{"content":"2025年目标规划 1、通过英语四级和六级\n2、准备下半年的教师资格证考核\n3、坚持一周3练\n4、论文有明显进展\n","date":"2025-02-17T00:00:00Z","image":"https://hzgbbq.github.io/ZGblog/p/2025%E7%9B%AE%E6%A0%87%E8%A7%84%E5%88%92/title_hu_8283ab3bde103be3.jpg","permalink":"https://hzgbbq.github.io/ZGblog/p/2025%E7%9B%AE%E6%A0%87%E8%A7%84%E5%88%92/","title":"2025目标规划"},{"content":"论文信息 标题：Relation-CNN: Enhancing website fingerprinting attack with relation features and NFS-CNN 发表年份：01 August 2024 发表期刊/会议：Expert Systems With Applications Volume 247 123236 DOI 链接: 10.1016/j.eswa.2024.123236 1、豆包AI脑图 2、论文背景介绍 1、隐私增强技术（pets） 如Tor, Shadowsocks等软件，在保护隐私的同时也给网络罪犯提供了网络防御的场所。所以发展网络指纹识别以便突破该保护。这使网络指纹攻击成为监测网络非法活动的重要手段\n2、网络指纹(WF)攻击概念和现状 概念：WF 攻击可通过流量分析识别用户访问的网页，其关键在于模型和特征的选择\n现状：现有 DL 攻击在性能提升上存在两个瓶颈。一是过度依赖深度神经网络（DNN）的自动特征提取能力，以往工作常直接将数据包方向或时间戳信息作为模型输入，未利用流量关系特征，导致有用判别信息丢失；二是现有 DL 攻击的 DNN 模型直接照搬计算机视觉（CV）中的模型，未针对减少信息损失进行优化，限制了攻击性能的提升\n3、本文做法 一方面，提出关系特征，通过设计算法构建交通实例图（TIG），从数据包方向序列中手动提取关系特征\n另一方面，构建 NFS - CNN 框架，对 ResNet18 进行三项优化（入口块、下采样块和残差块）以减少信息损失，并设计特征增强和特征注意力块，引入特征注意力机制衡量不同通道数据对准确率的贡献\n3、威胁模型 该论文中使用的典型威胁模型，如图 1 所示，包括五个实体：用户（受害者）、攻击者（敌手）、Tor 网络、网页和加密流量\n在这个场景中，攻击者是本地的、被动的网络层敌手。“本地” 意味着攻击者位于用户和防护节点之间；“被动” 表示攻击者不能延迟、丢弃、修改或解密流量，而只能记录流量。这两个特点显示了网站指纹攻击易于实施，同时也增强了其潜在威胁\n具体来说，攻击者需要收集一系列的流量样本，每个样本由访问一个网页时产生的数据包序列及其时间戳组成，以训练一个预定义的模型。如果流量样本来自对攻击者感兴趣的被监控网页的访问，则称为监控样本；如果网页是未被监控的，则称该样本为未监控样本。\n论文中还评估了网站指纹分类器在两种设置下的情况：\n封闭世界设置：所有收集的样本都属于被监控的网站。 开放世界设置：同时包含监控样本和未监控样本。 4、相关工作 1、WF攻击 从训练数据的规模分，WF攻击可分为低数据和典型两种。前者是基于有限的训练数据集，本文关注后者，有足够多的训练数据。\nWF攻击应该优化分类器的模型或提取更高质量的特征。\n三种特征提取方式\na、手动特征提取(传统机器学习)\n在早期 HTTP 1.0 时代，手动提取资源长度等特征可有效区分流量。但随着 HTTP 1.1 出现，研究者开始寻求更细粒度特征，如数据包长度、CUMUL 等。典型攻击如 Wa-KNN 手动提取大量特征，在特定数据集上取得较高准确率；Ha-KFP 利用随机森林提取特征并选择重要特征作为输入\nb、自动特征提取（深度学习）\n先前文献提出多种基于深度神经网络（DNN）的攻击，如使用卷积神经网络（CNN）、堆叠去噪自编码器（SDAE）、长短期记忆网络（LSTM）等，仅将数据包的时间戳、方向或方向时间戳作为输入，特征由 DNN 自动提取，但不同攻击因网络能力不同准确率有所差异\nc、混合特征提取攻击\n自动特征提取攻击受限于 DNN 和使用的特征，手动特征提取攻击依赖专家知识，因此本文提出 Relation-CNN 这种混合特征提取攻击，同时指出 Var-CNN 也是一种混合特征提取攻击，但与 Relation-CNN 设计不同\n5、从加密流量中提取关系特征 1、为什么需要额外提取关系特征的原因： 如图fig2\n绿色的A和橙色的T是同一个训练样本，橙色T由于网络波动第二和第三包的顺序掉换了位置。\n出现了与蓝色的卷积核卷积的输出值不同，这就导致了无法判断A和T是否为同一类，导致判别信息的丢失。\n2、形式化关系特征的定义： 假设：\n包序列S\u0026lt;p1,p2,\u0026hellip;pn\u0026gt;是访问网站的用户生成的\n攻击者从pi中提取数据包的方向di（i= 1，2，\u0026hellip;\u0026hellip;,n）\n如果di = 1,则表示pi是用户向服务器发送的包\n如果di = -1，则表示pi是服务器发送给用户的包\n因此，攻击者就能得到方向向量F\u0026lt;d1,d2,\u0026hellip;dn\u0026gt;\n要得到关系特征\n攻击者需要将相同方向的连续分组组成一个个突发块\n从而得到一个突发序列\u0026lt;B1,B2,\u0026hellip;Bk\u0026gt;,Bk可表示为\u0026lt;di,\u0026hellip;,dj\u0026gt;(1\u0026lt;= i,j,k \u0026lt;=n)\n关系特征表示为\u0026lt;r00,r01,\u0026hellip;,rij,\u0026hellip;,rnn\u0026gt;, (1 ≤ 𝑖, 𝑗 ≤ 𝑛)\nrij表示pi和pj之间的关系\n当i = j 时，rij = 1。\n当 i ≠ j 时，a、pi 和 pj 相邻且在同一个突发块时；b、pi 和 pj不在同一个突发块，但位于突发块头或块尾时， rij = 1\n其他情况，rij = 0。\n3、流量提取的3个步骤 1、构建流量实例图\n图为无向无权图\n从fig3变到fig4；fig4中黑线表示突发中的数据包内部链接；红线表示突发间的第一个包互相连以及最后一个包互相连；绿线则数据包的自连接\n2、生成邻接矩阵\nfig4中有相连的节点，则被认为它们之间存在某种关系，则对应表值为1，反之则值为0.\n3、构建关系向量\n为了将关系特征输入到WF攻击模型中，需要将相邻矩阵转换为行一阶向量。如图fig5\n如果输入向量的要求长度小于矩阵中总值的数量，则丢弃其余值\n4、关系特征的优势\n如图fig6,纠正能力强\n6、NFS-CNN 1、概述： NFS-CNN定义了四个块：NResNet18；feature-enhancing；feature-attention；classification；\nNFS-CNN可处理两种类型的向量\n第一种：被用于输入到NFS-CNN的特征提取器来自动学习新概念；内容包括方向、时间戳、关系向量\n第二种：统计向量，不需要进一步的特征学习\n四个块的作用\nNResNet18:从第一种向量中学习高维特征的自动特征提取器\nfeature-enhancing：可用于第二类向量的数据增强\nfeature-attention：重新定义来自不同通道的数据对结果的贡献\nclassification：对FA(feature-attention)的输出进行处理，得到预测结果\n四个块的关系，如fig7所示，NResNet18和feature-enhancing分别对两种向量进行处理，再输出到feature-attention处理，最后输出到classification处理。\n2、NResNet18： NResNet18是作者对传统CV中的ResNet18进行优化修改后得出来得层\nResNet18得结构图fig8\n优化点一：优化入口块 优化关键点：入口块的卷积层核大小为1 x 7（即入七出一），造成输出损失可能有点多。\n输出计算一般原理\n设输入向量大小为L，卷积核大小为k，填充大小为p，步长为s。 首先，考虑卷积核在输入向量上滑动的过程。卷积核每次滑动的步长为s，从输入向量的起始位置开始，直到不能再滑动为止。 当卷积核在输入向量上滑动时，对于每个位置，卷积核与输入向量的对应部分进行逐元素相乘并求和，得到一个输出值。 计算输出大小的关键在于确定卷积核可以在输入向量上滑动的次数。在考虑填充的情况下，输入向量的实际可处理长度变为L+2p（在两端添加填充）。 那么，卷积核可以滑动的次数可以通过以下公式计算：n = (L+2p - k)/s + 1。这个公式的含义是，先计算在考虑填充后的输入向量长度上，卷积核能够完整覆盖的次数(L+2p - k)/s，然后再加上起始位置的一次，得到总的滑动次数，也就是输出的大小。 优化点二：优化下采样块 优化措施：采用在downsamping 层之前多加一个 max - pooling 层并调整参数\n优化原理：\n1、max - pooling 层的特性与作用 数据降维与特征提取：其主要作用是对输入数据进行降维处理。它通过在一个局部区域（例如论文中设置的核大小为 1×3 的区域）内选取最大值作为输出，能够有效地减少数据量，同时保留数据中的显著特征\n滑动窗口机制与信息保留：max - pooling 层的滑动窗口机制（步长为 2，填充大小为 1）在优化过程中起到了关键作用。滑动窗口以步长 2 在输入向量上移动，每次覆盖一个 1×3 的区域并选取最大值。这种方式使得输入向量中的每个元素都有机会被考虑到，并且由于填充大小为 1，在边界处也能较好地处理数据，避免了边缘信息的过度丢失。\n优化点三：优化残缺块 优化措施：引入分组卷积（grouped convolution）技术，在保持或提升准确性的同时降低复杂度\n分组卷积原理引入 分组概念阐述：核心思想是将输入通道划分为若干个组（在本研究中，超参数，即将输入通道分为两组）\n优势分析 降低计算复杂度：\n在标准卷积中，计算量与输入通道数、输出通道数以及卷积核大小等因素相关（计算复杂度大致为）O(C * Cout * k^2)。而在分组卷积中，由于每个组内的计算相对独立，计算复杂度变为O(C/G * Cout * k^2).\n残差块中的应用\n1、替换卷积操作：在 ResNet18 的每个残差块中，对第二个卷积进行替换，采用上述分组卷积技术。具体而言，将原本的卷积层替换为分组卷积层，使得输入通道在分组后分别进行卷积计算，然后将结果进行拼接（concatenate），形成新的输出特征。\n2、保持残差块结构完整性：在进行分组卷积替换时，需要确保残差块结构的其他部分与之兼容，以保证整个网络的正常运行。这包括对输入和输出的维度进行适当调整，确保在经过分组卷积操作后，残差块的输入和输出能够与网络中的其他层正确连接，维持数据在网络中的顺畅流动。例如，需要保证分组卷积后的输出通道数与后续层的输入通道数匹配，以及在进行跳跃连接（shortcut connection）时，输入和输出的特征图大小和通道数相同。\n3、The feature-enhancing block： 作用：处理统计向量，使该层的输出形状与NResNet18一致。\n内容：分为四层，分别为：a convolutional layer；a global average pooling layer； a batch normalization layer；a relu layer。\na global average pooling layer为下一个块的SE机制做了Squeeze 操作（全局平均池化）操作。\n4、The feature-attention block 主要用于动态调整不同通道特征对分类结果的贡献，从而提高网络对流量数据的分类准确性\n具体做法：引入 Squeeze - Excitation（SE）机制\n1、Squeeze 操作（全局平均池化）：在 SE 机制中，首先通过全局平均池化对输入向量的每个通道进行操作，将每个通道的特征图转换为一个单一的数值，这个数值可以看作是该通道特征在整个输入数据上的全局描述符，能够表达整个通道数据的整体信息。\n例如，对于一个形状为(batchsize x C x H x W)（在处理二维图像数据时，H和W分别表示高度和宽度；在处理一维流量数据时，可将其视为(batchsize x C x 1 x 1）的输入张量，全局平均池化会在H x W（或1 X 1）的维度上进行平均计算，得到一个形状为batchsize x C的输出张量，每个元素代表对应通道的全局信息。\n（该操作实际是在feature-enhancing block的a global average pooling layer中完成）\n2、Excitation 操作（自适应重校准）：\n在得到每个通道的全局描述符后，通过一个瓶颈神经网络（包含两个全连接层，中间使用 ReLU 激活函数，周围是非线性操作）来实现 excitation 操作。这个瓶颈神经网络的作用是对通道间的依赖关系进行充分建模，根据输入数据的特征动态地为每个通道生成一个权重系数。\n5、The classification block 作用：\n进行最终分类决策：分类模块的核心作用是利用输入的特征数据进行分类计算，以确定每个测试样本属于相应类别的概率。它通过使用两个全连接层来实现这一功能。第一个全连接层对输入的高维特征进行映射和转换，将其压缩到一个相对较低维的空间，从而提取出更具代表性的特征信息。然后，第二个全连接层根据第一个全连接层的输出，计算每个样本属于各个类别的概率分布。在这个过程中，全连接层的参数通过训练过程进行学习和优化，使得网络能够根据输入特征准确地预测样本的类别。例如，在识别不同网站的流量时，分类模块会根据输入特征判断该流量样本最有可能属于哪个网站类别，从而实现对网站指纹的准确识别。\n输入：\n来自特征注意力模块（FA）的输出：经过特征注意力模块处理后的特征数据是分类模块的主要输入。特征注意力模块通过动态调整不同通道特征的贡献，已经对输入数据进行了有效的特征表示优化。这些经过重新校准的特征数据包含了丰富的信息，能够更好地反映输入流量样本的特征模式，为分类模块提供了高质量的输入，有助于提高分类的准确性。\n输出：\n预测向量：分类模块的输出是一个预测向量，其形状为batchsize x numclasses，其中batchsize表示一次处理的样本数量，numclasses表示数据集中网站类别的总数。预测向量中的每个元素代表相应样本属于某个类别的概率。例如，如果数据集中有 100 个不同的网站类别，那么预测向量中的每个元素就是一个样本属于这 100 个类别中某一个类别的概率值。\n7、Relation-CNN 如图所示，分为两个阶段：训练阶段和测试阶段\n1、训练阶段\n第一步：程序从每个训练样本中获取4个向量\u0026mdash;\u0026mdash;方向、时间戳、关系和统计向量，其中前三个向量输入到NResNet18层处理；统计向量输入到feature-enhancing层进行处理。\n第二步：根据NFS-CNN的输出计算交叉熵损失值，并基于NFS-CNN的优化策略更新参数，直到损失值收敛\n第三步：将收敛点处的模型参数辅助到测试阶段，然后进行冻结。\n2、测试阶段\n在测试阶段，CNN的参数将被冻结，不在进行更新变化。与训练阶段一样要对测试样本进行处理获得需要的四个向量进行输入。\n根据每个测试样本对应的输出向量，测试程序可以直接预测其标签。\n文中还提到了relation-cnn是一种新的半自动WF攻击，它的手动部分主要体现在特征提取的部分（尤其是关系特征的提取）；它的自动化主要体现在它模型训练和测试的计算过程是依赖于自动化的神经网络计算。\n训练参数的优化策略：Adam 优化器\nAdam 优化器结合了动量优化策略和自适应优化策略，其优点包括：\n对学习率不敏感，可以傻瓜式学习，省去了人工调参的麻烦，不需要手动调整超参数。 选择 Adam 优化器而不用其他策略的原因可能是它在许多情况下都能取得较好的效果，能够自动调整学习率，适应不同的参数更新需求，从而帮助模型更有效地收敛。\n8、实验评估 1、实验设置 数据集：\n使用九个数据集，涵盖未防御和防御场景，如 Wang - CW、Wang - OW、Sirinam - CW1000、Sirinam - OW、WTF - PAD、W - T (Sim)、Overdorf - Onion 等。\n模型选择与实现：\n选择 Wa - KNN、Ha - KFP、Ri - SDAE、Si - DF、Ra - TikTok 等作为基线攻击模型，涵盖深度学习和传统机器学习技术，具有代表性。 使用 PyTorch 实现 Relation - CNN，在 NVIDIA RTX 6000 工作站上运行，采用 Adam 优化器，遵循官方实现步骤处理数据，包括提取方向、时间戳、关系和统计向量，并进行预处理。 指标：\n封闭世界评估使用准确率衡量攻击性能；开放世界评估使用精确率 - 召回率（P - R）曲线、真正率（TPR）、假正率（FPR）、贝叶斯检测率（BDR）等指标。\n2、关系特征评估 确定关系特征数量：在 Sirinam - CW1000 数据集上测试不同数量关系特征对 Relation - CNN 准确率的影响，发现准确率随特征数量增加而上升，最终确定使用 5000 个关系特征。\n比较评估\n进行两项比较评估，将关系特征分别与方向向量、时间戳向量组合输入分类器（Si - DF 和 NFS - CNN），结果表明关系特征能提高分类器准确率，且在样本量较少的数据集上提升更明显，证明关系特征提供了新的判别信息，且难以被 DNN 自动学习。 信息泄漏分析\n利用 WeFDE 工具进行信息泄漏分析，发现关系特征泄露大量信息且具有冗余性，但提供了独特信息，其独特信息未被现有特征包含，这解释了添加关系特征可提高模型准确率的原因。\n从图中可以看到的是大多数关系特征的信息泄漏都大于1位，该比率大于方向和时间戳特征。特别是对于时间戳特性，大多数特性泄漏的信息少于1位。此外，还可以观察到一个有趣的现象，**即连续关系特征，没有泄露信息。**从此现象可以得到关系特征具有冗余性。猜测若能解决该冗余性有可能使关系特征泄露出更多信息。\n如上图：关系特征泄露的信息是与其他特征泄露的不同的，并且除了冗余的（深灰色）信息，关系特征只属于一个集群。\n3、Relation - CNN 评估 NFS - CNN 变体比较\n比较不同输入向量的 NFS - CNN 变体准确率，结果表明添加更多向量输入通常能提高准确率，Relation - CNN 始终表现最佳，凸显其有效性。\n封闭世界评估（无防御数据集）\n在无防御数据集上，Relation - CNN 准确率高于其他基线攻击，在样本量较少的数据集上优势更明显，如在 Sirinam - CW100 上比其他基线攻击高出一定比例，表明其数据高效且鲁棒。\n封闭世界评估（有防御数据集）\n在有防御数据集（WTF - PAD 和 W - T (Sim)）上，Relation - CNN 在两种防御下均取得最佳准确率，超过最佳基线攻击一定比例，说明这两种防御对 Relation - CNN 无效。\n开放世界评估\n第一个实验：训练样本和测试样本固定，通过 P - R 曲线比较不同攻击在开放世界场景下的性能，Relation - CNN 召回率和精确率性能最佳。\n第二个实验：固定监测的训练样本和测试样本，调整未监控训练样本数量的实验中，Relation - CNN 在 TPR、FPR 和 BDR 指标上始终表现最好，进一步证明其鲁棒性。\n4、与 Var - CNN 比较 Relation - CNN 与 Var - CNN 对比：\nRelation - CNN 在网络骨干优化（对 ResNet18 进行优化，减少信息损失）、融合机制（引入特征注意力机制，自动调整特征贡献）和使用特征（包含独特关系特征）三个方面优于 Var - CNN。\n比较实验：\n在无防御和有防御数据集上进行比较实验，Relation - CNN 在所有设置下均优于 Var - CNN，尤其在样本量较少的数据集和洋葱数据集上优势更明显，在有防御数据集上也表现出色，充分证明其优越性。\n问题汇总 1、本文中做实验隐私增强技术的环境是怎样的？\n2、本文中的流量分析和提取主要提取了什么?\n3、本文中的关系特征是如何提取的？\n4、传统CNN与NFS-CNN、Relation-CNN与Var-CNN的不同点和相同点？\n5、在注意力块中的Excitation 操作具体如何实现的？看不懂！！！特别使5.4.2部分\n6、什么是瓶颈神经网络？\n","date":"2024-11-26T00:00:00Z","image":"https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBrelation-cnn_enhancing_website_fingerprinting_attack_with_relation/title_hu_e5b31d09454e9677.png","permalink":"https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBrelation-cnn_enhancing_website_fingerprinting_attack_with_relation/","title":"论文阅读：Relation-CNN_Enhancing_website_fingerprinting_attack_with_relation"},{"content":"相关知识点补充 1、BGPKIT的作用及使用 2、CAIDA的作用及使用 3、IXP路由服务器 4、BGP中的对等信息\t32张图详解BGP路由协议：BGP基本概念、BGP对等体、BGP报文类型、BGP状态机等-腾讯云开发者社区-腾讯云 (tencent.com) 5、Gao-Rexford模型 6、ASRank引文[18] 7、监督二元分类器 8、SEAL框架 9、GNN模型\n疑惑点： 6、design中四个场景 7、design中的四个特征\n","date":"2024-09-27T00:00:00Z","permalink":"https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%A3%80%E6%B5%8B%E4%BC%AA%E9%80%A0-bgp-%E5%8A%AB%E6%8C%81%E7%9A%84%E7%B3%BB%E7%BB%9F/","title":"论文阅读：检测伪造 BGP 劫持的系统"},{"content":"论文信息 标题：Backdoor Attack on Deep Learning-Based Medical Image Encryption and Decryption Network 发表年份：05 October 2023 发表期刊/会议：IEEE Transactions on Information Forensics and Security(Volume: 19)Page(s): 280 - 292 DOI 链接: 10.1109/TIFS.2023.3322315 摘要概述 本文主要研究了对医疗影像加密和解密模型的攻击，提出了一种加解密网络后门攻击范式，并分别针对加解密场景设计了相应的攻击方式。\n在攻击加密模型中，采用了后门鉴别器，它与普通鉴别器进行随机训练，以混淆加密过程，最终导致加密失败。\n在解密场景中，替换了部分子网参数，解密带有触发器的图像时，使图像解密失败。\n本文还做了两点革新：一是考虑到参数替换会导致模型性能下降，采用了模型剪枝来进一步减少参数替换量，从而增强攻击性能；二是采用图像隐写术为每张图像生成不可见的触发器，提高后门攻击的隐蔽性。\n研究背景与动机 研究背景 1、医疗图像中包含大量敏感信息，如患者的病历、诊断图像等，这些数据一旦泄露可能带来严重的隐私风险。因此，医疗图像的加密和解密技术一直是医疗信息安全领域的重点研究方向。\n2、近年来，基于深度学习的医疗图像加密方法，如CycleGAN等，能够有效地实现图像的风格迁移，将医疗图像转换为难以识别的加密图像，从而提升图像的安全性。然而，现有的加密方法仍然可能受到攻击，尤其是在训练阶段引入后门的情况下。\n动机 作者通过通过三篇引文10、22、25，看到了目前的后门攻击方法主要使针对监督模型，并且难以应用于半监督和无监督。同时看到了在在基于深度学习的医疗影像安全领域在抵御后门攻击能力上的缺陷。\n论文方法与技术 相关工作 A.基于深度学习的医学图像加解密网络的发展历程 深度学习在医学图像加解密中的引入：\n最早基于深度学习的医学图像加解密技术是采用卷积神经网络（CNN）进行特征提取，并将其用于加密。研究人员使用CNN从虹膜图像中提取特征，并通过纠错编码对其进行加密（Li等，2018年）。此方法通过异或操作进行图像加密。 深度学习与混沌映射结合：\n一些学者进一步发展了将深度学习与混沌映射结合的方法来增强加密效果。例如，Maniyath等人提出了一个强大的深度神经网络，该网络通过混沌映射来加密图像，能有效抵抗多种攻击。 Cycle-GAN 在医学图像加解密中的应用：\nCycle-GAN 被用于将医学图像的风格转化为随机分布像素的密文图像，作为加密解密网络的核心架构之一。该方法成功实现了医学图像的风格迁移和加解密。 B.后门攻击 后门攻击概述：\n后门攻击是指攻击者在模型训练过程中植入后门，使得模型在遇到特定触发器时产生预期的行为，而在没有触发器的情况下，模型表现正常。Badnets 是最早提出的后门攻击模型之一，针对图像分类任务有效地演示了这种攻击。 动态后门攻击：\n动态后门攻击通过改变触发器的模式和位置来增加攻击的隐蔽性。例如，Salem等人提出了动态后门攻击策略，触发器的模式和位置可以变化，增加了检测难度。 多样化后门攻击的应用：\n除了图像分类任务外，后门攻击还可以应用于生成模型、语言模型等复杂系统。例如，张等人通过触发短语让生成模型生成特定字符串或冒犯性文本。 对深度学习加密网络的后门攻击：\n大多数研究集中在分类模型的后门攻击，然而加密和解密网络同样面临后门攻击威胁。由于加密解密任务缺乏标签，传统的后门攻击方法难以适用，新的攻击方式急需开发。 对生成模型的挑战：\n现有的后门攻击方法对生成模型攻击存在困难，生成模型的输入需要满足多种特定限制，且现有的推理攻击难以直接应用于生成网络。 C.图片隐写术发展历程 隐写术简介：\n隐写术是一种通过将信息隐藏在另一种数据（如图片、音频、视频等）中，避免被察觉的技术。最早提出的隐写术方法之一是**最低有效位（LSB）**技术。它通过用秘密图像的n个最重要位替换覆盖图像的n个最不重要位来实现信息嵌入。 基于频域的隐写术方法：\n除了LSB技术，研究人员还开发了在不同频域中嵌入信息的方法，例如离散傅里叶变换（DFT）、离散余弦变换（DCT） 和离散小波变换（DWT）。这些方法虽然复杂一些，但比LSB更可靠且不易被检测到。 基于深度学习的隐写术模型：\n最近，深度学习被应用于隐写术中，超越了传统技术的性能。Zhu等人开发了基于自编码器的网络来实现水印嵌入与提取。Ahmadi等人在此基础上引入了残差连接和CNN变换操作模块，以便在任何变换空间中嵌入水印。 隐写GAN模型的引入：\nZhang等人使用生成对抗网络（GAN）提高了隐写图像的感知质量。该方法能更好地隐藏信息，且隐写图像与原始图像在视觉上几乎无差异。 隐写术在后门攻击中的应用：\nLi等人最早使用基于深度神经网络的图像隐写术生成隐蔽的后门触发器。这种攻击不仅难以被检测到，还能够绕过大多数现有的后门防御措施，因为它的触发器模式是针对具体样本的。 方法论 A.威胁模型 威胁场景：\n在加密网络的场景中，攻击者了解加密网络的训练过程，并且掌握部分训练数据，但不能更改网络结构。在受害者使用训练好的模型加密医学图像时，攻击者可以在输入图像上植入后门触发器，破坏加密性能。 在解密场景中，攻击者熟悉模型的结构和内存布局，但不参与加密网络的训练。攻击者可以修改解密网络的某些参数来插入子网络，从而在输入图像中嵌入触发器时激活后门攻击 。 攻击目标：\n加密网络：攻击目标是当输入图像中包含后门触发器时，网络无法将其转换为密文图像，而在没有触发器时，网络可以正常加密图像。 解密网络：当输入带有后门触发器的密文图像时，解密网络将输出与原始图像完全不同的图像；而当输入的密文图像不含触发器时，解密网络可以成功解密回原始图像 。 后门触发器：\n无论是加密还是解密场景，后门触发器作为攻击的标志，不应被人眼轻易识别。这种隐蔽性是后门攻击成功的关键因素。 D. Attack Encryption Network (攻击加密网络) 加密网络攻击简介 在攻击加密网络时，攻击者通过随机训练原判别器和后门判别器，使加密网络输出的图像接近原始图像，而不是生成密文图像。后门判别器的训练使带有后门触发器的输入破坏了加密过程。 网络训练过程 网络使用原始判别器、解密网络和后门判别器进行联合训练。对于不含触发器的输入，使用原判别器生成加密图像；对于含触发器的输入，通过后门判别器破坏加密过程。 E. Attack Decryption Network (攻击解密网络) 攻击方案概述 在攻击解密网络中，攻击者通过子网络替换部分解密网络的参数，使得当输入带有后门触发器的图像时，解密网络的性能被破坏，输出不可识别的图像。 通道替换与剪枝技术 为了减少参数替换的影响，攻击者使用通道剪枝技术，选择要替换的通道，以最小化对解密网络正常性能的影响。实验结果表明，使用剪枝策略能有效提高攻击性能，并减少对正常解密的干扰。 实验设计与结果 一、数据集 **数据来源：**数据集有美国国家医学图书馆提供，并且所有的X光片均来自美国卫生与公共服务部和中国深圳第三人民医院。\n**数据内容：**包含结核病表现得正常和异常胸部X光片以及相应得放射科医生读数。\n**数据集分类：**90%数据集用作训练数据集，10%得数据集用作验证数据集。\n二、实验设计图 三、实验评估 评估指标 结构相似指数（SSIM）\nSSIM（Structural Similarity Index Metric）是一种衡量两幅图像相似度的指标。它是通过将图像分解为不同的结构分量，来比较图像在亮度、对比度和结构上的差异。\n公式如下：\n**亮度比较l(x,y)：**用于衡量两幅图像亮度的差异\n**对比度比较c(x,y)：**用于衡量两幅图像对比度的差异\n**结构比较s(x,y)：**用于衡量两幅图像结构（如边缘、纹理）的差异\n峰值信噪比（PSNR）\nPSNR是一种基于均方误差（MSE, Mean Squared Error）的指标，描述了图像重建或压缩后的质量与原始图像的差距。它通过对原始图像与处理后的图像进行逐像素比较，计算出两者的差异，然后转化为信噪比的形式。\n公式如下：\n攻击成功率（ASR）与干净数据准确率（CDA）\nASR（攻击成功率，Attack Success Rate）是一种衡量指标，用来评估带有后门触发的样本是否能够成功使模型输出错误的结果。在医疗影像加密和解密网络的攻击中，ASR用于验证攻击能否成功破坏图像的加密或解密过程。\nCDA（Clean Data Accuracy，干净数据准确性）表示在所有未嵌入后门触发器的干净数据样本中，能够被正确加密和解密的图像比例。它是一种衡量网络在处理正常图像时加密和解密的准确性的方法\n攻击成功的评估标准\n对于加密网络，当SSIM大于0.7且PSNR大于20时，被视为加密失败。对于解密网络，当SSIM小于0.4且PSNR小于10时，解密被视为失败，从而确定攻击成功 .\n实验对比图 实验效果图如下：左边为攻击加密网络，右边为攻击解密网络\n两种攻击的数据结果\n后门攻击方法评估 攻击加密网络的评估 1、后门加密网络参数α：\n​\t在训练后门加密网络的过程中，α 是后门鉴别器在整个后门加密网络中出现的概率。上表可看到，随着α 的增大，SSIM和PSNR的值保持增大的趋势。这表明，当α 取较大值时，后门加密网络能够取得更好的性能，并且当α设 置为0.5时，后门加密网络能够取得最好的攻击性能。这也意 味着后门鉴别器应该考虑与起源鉴别器相同的概率。\n​\t另外，除了通过设置参数α来训练后门鉴别器和原始鉴别器之外，另一种方法是通过交叉训练的方式来训练后门和原始鉴别器。这意味着训练过程将采用本次普通鉴别器来训练后门加密网络，并且下次采用后门判别器，以替代方式进行训练。通过另一种方式训练后门加密网络，对带有触发器标记的图像进行加密，平均SSIM和PSNR分别为0.74和22.09，均低于使用参数α为0.5训练后门加密网络。可以说，与其他训练方法相 比，所提出的训练方法（使用α为0.5来训练后门鉴别器）可以获得更好的攻击性能。\n2、验证加入了后门的密文图像是否还能保持原有的加密安全性能\n通过直方图分析和熵分析两种方式进行分析\n直方图：\n原始X射线图像共有57600（240 * 240）个像素，像素分布更集中在值0和值255上。而密文图 像的像素分布是统一的范围为0到255，这对于防止统计分 析破解更加有效。\n图像信息熵：\n图像信息熵是图像灰度分布的统计特征。理想情况下，加密图像应与随机噪声相似，灰度分布均匀，理想值应为8。\n攻击解密网络的评估 1、信道替换比例η对解密网络的分析\n本实验采用第一层通道数作为子网替换的参数，并采用SSIM值作为评价指标来表征实验结 果。第一层共有32个通道，可用于替换的子网通道数设置 为1～8。从图9可以看出，随着待替换通道的增量，激活状 态下的SSIM值，代表后门解密网络解密出的带有后门触发 的密文图像，逐渐减小。这意味着攻击解密网络取得了巨 大成功（密文图像无法被正确解密）。非活动状态下的SSIM值，代表正确解密的无后门触发的密文图像，略有下降，但解密性能基本保持不变。当替换通道数达到4个时， 后门解密网络可以平衡活动状态和非活动状态之间的解密 性能。更换超过4层后，主动攻击的SSIM值仍在逐渐下降，这意味着攻击解密网络可以取得更好的攻击性能。然 而，非主动攻击的解密性能也大幅下降，这表明通过替换4 层以上，正确的解密过程仍然被破坏。因此，如果采用 12.5%（共4层，共32层）层数作为第一层的通道替换比例，则后门解密网络在兼顾攻击和解密的情况下可以达到 最佳性能。\n2、关于解密网络的剪枝影响分析\n图a是密文图像；图b是采用模型剪枝策略的结果；图c是采用随机选择策略的结果；图d和图e是驶入带有触发器的密文图像破坏解密性能的情况，其中图d是对应模型剪枝策略，图e对应随机选择策略\n上表中给出的是两种策略的量化结果\n结论与启示 1、首次提出了针对医学图像加解密网络的后门攻击范式\n2、对比之前的后门攻击，本文提出的后门攻击能成功运用于无监督模型\n3、论文不仅定义了一种攻击加密和解密网络的模式，还为增强这类模型的安全性提供了新的研究方向。其研究结果表明，现有的深度学习加密解密网络存在安全漏洞，这为未来的网络安全研究提供了重要的理论依据。\n个人评论与反思 ","date":"2024-09-23T00:00:00Z","image":"https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%8A%A0%E8%A7%A3%E5%AF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/title_hu_22ad342cf5a32604.jpg","permalink":"https://hzgbbq.github.io/ZGblog/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%8A%A0%E8%A7%A3%E5%AF%86%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/","title":"论文阅读：基于深度学习的医学图像加解密网络的后门攻击"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"https://hzgbbq.github.io/ZGblog/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu_e95a4276bf860a84.jpg","permalink":"https://hzgbbq.github.io/ZGblog/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"}]